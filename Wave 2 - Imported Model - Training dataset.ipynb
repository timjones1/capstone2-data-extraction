{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Contract Data Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokens import Token, Span, Doc\n",
    "from spacy import displacy\n",
    "from openpyxl import load_workbook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import wavefunctions as wf\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load spacy and pretrained model from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1c514cf2a90>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp.from_disk(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into pandas and start by looking at the times [extract] free text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_df = pd.read_excel('data\\Employee Train.xlsx',sheet_name=\"Training Dataset\")\n",
    "times_extract = contract_df['Times [Extract]']\n",
    "employee_ids = contract_df['Employee ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom extensions in Spacy to store structured information before adding it to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time extract extensions\n",
    "Doc.set_extension(\"specified_days\",getter=wf.get_days_per_week_model, force=True)\n",
    "Doc.set_extension(\"specified_hours\",default=0, force=True)\n",
    "Doc.set_extension(\"lunch_hours\",default=0,force=True)\n",
    "Span.set_extension(\"saved_hours\",default=0,force=True)\n",
    "Span.set_extension(\"saved_days\",default=0,force=True)\n",
    "\n",
    "#work on public holidays etxensions\n",
    "Doc.set_extension(\"work_none\",default=0, force=True)\n",
    "Doc.set_extension(\"work_normal\",default=0, force=True)\n",
    "Doc.set_extension(\"work_required\",default=0, force=True)\n",
    "Doc.set_extension(\"work_easter\",default=0, force=True)\n",
    "\n",
    "#Holiday extensions\n",
    "Doc.set_extension(\"hol_30x\",default=0, force=True)\n",
    "Doc.set_extension(\"dec_jan\",default=0, force=True)\n",
    "Doc.set_extension(\"leave_as_salary\",default=0, force=True)\n",
    "Doc.set_extension(\"pro_rata\",default=0, force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(times_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assumed(specified_time,timeframe=\"days\"):\n",
    "    \n",
    "    multiplier = 1\n",
    "        \n",
    "    if timeframe == \"hours\":\n",
    "        multiplier = 7.5\n",
    "        \n",
    "    if specified_time == 0:\n",
    "        return 5 * multiplier\n",
    "    else: return 0\n",
    "\n",
    "def get_blended(specified_time,timeframe=\"days\"):\n",
    "    \n",
    "    multiplier = 1\n",
    "        \n",
    "    if timeframe == \"hours\":\n",
    "        multiplier = 7.5\n",
    "    \n",
    "    if specified_time == 0:\n",
    "        return 5 * multiplier\n",
    "    else: return specified_time\n",
    "\n",
    "\n",
    "preds = pd.DataFrame(columns = [\"text\",\n",
    "            'Days per week specified', 'Days per week assumed',\n",
    "            'Days per week blended', 'Hours per week specified',\n",
    "            'Hours per week assumed', 'Hours per week blended'])\n",
    "  \n",
    "for idx,doc in enumerate(docs):\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        \n",
    "        wf.extract_specified_times(ent)\n",
    "    \n",
    "    wf.get_days_per_week_model(doc)\n",
    "    wf.get_hours_from_doc_ents(doc)\n",
    "    \n",
    "    spec_days = doc._.specified_days\n",
    "    spec_hours = doc._.specified_hours\n",
    "    \n",
    "    preds.loc[idx] = [doc.text,spec_days,\n",
    "                      get_assumed(spec_days),\n",
    "                      get_blended(spec_days),\n",
    "                      spec_hours,\n",
    "                      get_assumed(spec_hours,\"hours\"),\n",
    "                      get_blended(spec_hours,\"hours\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_results(preds, actuals):\n",
    "    '''\n",
    "    Function to check accuracy the of extracted data to the actual values stored in contract_df\n",
    "    '''\n",
    "    cols = preds.columns\n",
    "    \n",
    "    for t in [\"text\",\"days_holiday\",\"pro_rata\",\"days_entitled\",\"days_phol\"]: \n",
    "        if t in cols:\n",
    "            cols = cols.drop(t)\n",
    "    \n",
    "    actuals = actuals[cols].fillna(0).reset_index()\n",
    "    \n",
    "    rows = len(preds)\n",
    "    features = len(cols)\n",
    "    score_matrix = np.zeros((rows,features))\n",
    "    \n",
    "    for idx,col in enumerate(cols):\n",
    "        score_matrix[:,idx] = (preds[col] == actuals[col])\n",
    "    \n",
    "    return f\"{np.sum(score_matrix) / (rows*features) * 100:.1f}% accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how well the extraction is performing shows that we are getting classifying 99% of the training data correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'98.9% accuracy'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_results(preds,contract_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Days per week specified</th>\n",
       "      <th>Days per week assumed</th>\n",
       "      <th>Days per week blended</th>\n",
       "      <th>Hours per week specified</th>\n",
       "      <th>Hours per week assumed</th>\n",
       "      <th>Hours per week blended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The normal working hours are to be arranged, a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "10  The normal working hours are to be arranged, a...   \n",
       "\n",
       "    Days per week specified Days per week assumed  Days per week blended  \\\n",
       "10                      1.0                     0                    1.0   \n",
       "\n",
       "    Hours per week specified Hours per week assumed  Hours per week blended  \n",
       "10                       0.0                   37.5                    37.5  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[~(preds[\"Days per week blended\"] == contract_df[\"Days per week blended\"].fillna(0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The normal working hours are to be arranged, and will include a one hour lunch break. One day each week starts with a staff meeting at 8.3o during term time and 9.00 outside term time'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.loc[10,\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = contract_df.loc[17,'Times [Extract]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = contract_df\n",
    "export_df[['Days per week specified', 'Days per week assumed',\n",
    "            'Days per week blended', 'Hours per week specified',\n",
    "            'Hours per week assumed', 'Hours per week blended']] = preds[['Days per week specified', 'Days per week assumed',\n",
    "            'Days per week blended', 'Hours per week specified',\n",
    "            'Hours per week assumed', 'Hours per week blended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Employee Train.xlsx\"\n",
    "writer = pd.ExcelWriter(path, engine='openpyxl')\n",
    "writer.book = load_workbook(path)\n",
    "writer.sheets = dict((ws.title,ws) for ws in writer.book.worksheets)\n",
    "contract_df.to_excel(writer,sheet_name=\"Training Dataset\", startrow=2,index=False, header=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data from the work on public holidays [Extract]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Spacy and the Matcher class to allow extra flexibility in matching text patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_extract = contract_df[\"Work on Public Holidays [Extract]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_normal_match(matcher, doc, id, matches):\n",
    "      doc._.work_normal = 1\n",
    "        \n",
    "def on_required_match(matcher, doc, id, matches):\n",
    "      doc._.work_required = 1\n",
    "        \n",
    "def on_easter_match(matcher, doc, id, matches):\n",
    "      doc._.work_easter = 1\n",
    "\n",
    "public_matcher.add(\"normal_days\", on_normal_match, [{\"LOWER\": \"normal\"},{\"LOWER\": \"working\"}, {\"LOWER\": \"days\"}])\n",
    "public_matcher.add(\"required_to_work\", on_required_match, [{\"LOWER\": \"required\"}, {\"lower\": \"to\"},{\"lower\": \"work\"}])\n",
    "public_matcher.add(\"easter_work\", on_easter_match, [{\"LOWER\": \"easter\"}, {\"lower\": \"revision\"}])\n",
    "\n",
    "preds_public = pd.DataFrame(columns = [\"text\",\n",
    "            'Silent re Public Holiday Arrangements', 'Public Holidays during term are normal working days',\n",
    "            'Public Holidays during Easter Revision course are normal working days', \n",
    "            'Working on Public Holidays may be required'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_docs = nlp.pipe(public_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,doc in enumerate(public_docs):\n",
    "    if doc.text == \"None\":\n",
    "        doc._.work_none = 1\n",
    "        \n",
    "    matches = public_matcher(doc)\n",
    "    \n",
    "    preds_public.loc[idx] = [doc.text, doc._.work_none, doc._.work_normal,\n",
    "                       doc._.work_easter, doc._.work_required]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple matching of text phrases gives 100% accuracy, it may be worth reviewing and making this more robust to text/spelling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100.0% accuracy'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_results(preds_public,contract_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data from the Holiday Entitelment [Extract]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a bag of words model with TfidfVecotrizer and a Decision Tree Classifier to predict the type of holiday clause for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holiday entitlement helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not ideal repeated calls to doc.ents need to have this saved.\n",
    "\n",
    "def get_days_holiday(doc):\n",
    "    '''\n",
    "    '''\n",
    "    for ent in doc.ents:\n",
    "        if(\"days\" in ent.lower_ and check_nearby_tokens(ent[0],\"entitled\",[4,0])):\n",
    "            return wf.get_number_from_token(ent[0])\n",
    "        \n",
    "def get_days_entitled(doc):\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if(\"days\" in ent.lower_ and check_nearby_tokens(ent[0],\"entitlement\",[4,0])):\n",
    "            return wf.get_number_from_token(ent[0])\n",
    "        \n",
    "def get_days_phol(doc):\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if(\"days\" in ent.lower_ and (check_nearby_tokens(ent[0],\"public\",[0,4]) or \n",
    "           check_nearby_tokens(ent[0],\"bank\",[0,4]))):\n",
    "            return wf.get_number_from_token(ent[0])\n",
    "\n",
    "def check_nearby_tokens(token,search_word,n_range):\n",
    "    '''\n",
    "    For a given token, check if a given search_word string is present within\n",
    "    a given n_range of surrounding tokens, return True if found otherwise False\n",
    "    \n",
    "    token: a spacy token object\n",
    "    search_word: a string object to search for.\n",
    "    n_range: list of 2 ints, giving the number of tokens before and after to \n",
    "             check\n",
    "    '''\n",
    "    if token.i < n_range[0]:\n",
    "        start = 0\n",
    "    else: start = token.i - n_range[0]\n",
    "    \n",
    "    finish = token.i + n_range[1]\n",
    "    \n",
    "    return (search_word in token.doc[start:finish].lower_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text for information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_extract = contract_df[\"Holiday Entitlement [Extract]\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider removing common words via a stop words list to bring down the size of sparse matrices after tfidf processing, check if this improves accuracy as opposed to using max_df for a similar outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words0 = [\"you\",\"are\",\"to\",\"at\",\"where\",\"we\",\"will\",\"be\",\"your\"]\n",
    "stop_words1 = [\"depending\",\"actually\",\"entitlement\",\"equivalent\",\"calculated\",\"calculating\",\"involve\",\"depending\",\"you\",\"are\",\"entitled\",\"to\",\"taken\",\"at\",\"where\",\"we\",\"require\",\"work\",\"will\",\"be\",\"paid\",\"your\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(ngram_range = (1,3),stop_words=stop_words1,use_idf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add categories to the target variable for each of the different common holiday clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = contract_df[\"Holiday pro-rata to full-time 35 days plus 8 public holidays (43)\"].fillna(0) * 6\n",
    "is_hol_pro_33 = contract_df[\"Holiday pro-rata to full-time 33 days including 8 public holidays (or 25+8) (33)\"]==1\n",
    "is_hol_30x = contract_df[\"Holiday 6.12 weeks including public holidays (30.x)\"]==1\n",
    "is_hol_pro_28 = contract_df[\"Holiday pro-rata by hrs to full-time 5.6 weeks including public holidays (or 20+8) (28)\"]==1\n",
    "is_hol_pro_44 = contract_df[\"Holiday pro-rata to full-time 35 days plus 9 public holidays (44)\"]==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine similar and rare categories and correct an unclassified training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[is_hol_pro_33] = 5 # (33)\n",
    "y[is_hol_pro_28] = 3 # (28)\n",
    "y[is_hol_pro_44] = 6 # combined with (43) as very similar except for days\n",
    "y[is_hol_30x] = 4 # (30.x)\n",
    "y[y==0] = 4 # set remaining unclassified example to (30x) as it was not categorized in the xls file  \n",
    "y_prep = y[~(y==4)] # remove all (30.x) examples from y that can be categorized from text lookup.\n",
    "X_prep = holidays_extract[~(y==4)] # remove all (30.x) examples from holidays extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that counts of values match those in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_prep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c7c7ed2f753d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_prep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_prep' is not defined"
     ]
    }
   ],
   "source": [
    "y_prep.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre Process the training set through the TfIdf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_vectors = tf_vect.fit_transform(X_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a train test split to gauge initial accuracy of a tf-idf and DTC based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(holiday_vectors,y_prep,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hol_preds = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         3.0       0.92      1.00      0.96        12\n",
      "         5.0       1.00      0.50      0.67         2\n",
      "         6.0       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.97      0.83      0.88        19\n",
      "weighted avg       0.95      0.95      0.94        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,hol_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this accuracy works well across all the data by using cross validation include the tfidf vectorizer params in a gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pipeline to allow tfidf settings to be tuned at the same time as the DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('dtc', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    \n",
    "    \"dtc__max_depth\" : [5,7,None],\n",
    "    \"dtc__max_features\" : [None,0.8],\n",
    "    \"tfidf__ngram_range\" : [(1,3),(1,4)],\n",
    "    \"tfidf__stop_words\" : [None,stop_words1],\n",
    "    # \"tfidf__use_idf\" : [True, False],\n",
    "     \"tfidf__max_df\" : [1.0,0.9],\n",
    "    # \"tfidf__min_df\" : [0.0,0.25]\n",
    "}\n",
    "\n",
    "gridCV = GridSearchCV(pipeline,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_...\n",
       "                         'tfidf__max_df': [1.0, 0.9],\n",
       "                         'tfidf__ngram_range': [(1, 3), (1, 4)],\n",
       "                         'tfidf__stop_words': [None,\n",
       "                                               ['depending', 'actually',\n",
       "                                                'entitlement', 'equivalent',\n",
       "                                                'calculated', 'calculating',\n",
       "                                                'involve', 'depending', 'you',\n",
       "                                                'are', 'entitled', 'to',\n",
       "                                                'taken', 'at', 'where', 'we',\n",
       "                                                'require', 'work', 'will', 'be',\n",
       "                                                'paid', 'your']]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridCV.fit(X_prep,y_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the best score from the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridCV.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gridCV.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check detailed Gridsearch results, a large variety of parameters give the same top score of 96 using a decision tree. Manual examination of the cases that fail to be classified properly in split0 could be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_dtc__max_depth</th>\n",
       "      <th>param_dtc__max_features</th>\n",
       "      <th>param_tfidf__max_df</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>param_tfidf__stop_words</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.017401</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>[depending, actually, entitlement, equivalent,...</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'dtc__max_depth': 7, 'dtc__max_features': 0.8...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.077746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.018197</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.077746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.028192</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'dtc__max_depth': 5, 'dtc__max_features': 0.8...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.077746</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>[depending, actually, entitlement, equivalent,...</td>\n",
       "      <td>{'dtc__max_depth': 7, 'dtc__max_features': 0.8...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.073030</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.073030</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.019992</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.084327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.021392</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>[depending, actually, entitlement, equivalent,...</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.084327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.025108</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'dtc__max_depth': None, 'dtc__max_features': ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.084327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "41       0.017401      0.003843         0.004606        0.000794   \n",
       "28       0.019600      0.001026         0.005820        0.001360   \n",
       "44       0.018197      0.000755         0.004600        0.001020   \n",
       "14       0.028192      0.003126         0.008214        0.001313   \n",
       "31       0.019209      0.001598         0.005191        0.000973   \n",
       "36       0.019400      0.001851         0.004999        0.001276   \n",
       "40       0.019992      0.001115         0.005206        0.000757   \n",
       "39       0.021392      0.003541         0.004793        0.000768   \n",
       "38       0.025108      0.002056         0.006787        0.000754   \n",
       "\n",
       "   param_dtc__max_depth param_dtc__max_features param_tfidf__max_df  \\\n",
       "41                 None                     0.8                   1   \n",
       "28                    7                     0.8                 0.9   \n",
       "44                 None                     0.8                 0.9   \n",
       "14                    5                     0.8                 0.9   \n",
       "31                    7                     0.8                 0.9   \n",
       "36                 None                    None                 0.9   \n",
       "40                 None                     0.8                   1   \n",
       "39                 None                    None                 0.9   \n",
       "38                 None                    None                 0.9   \n",
       "\n",
       "   param_tfidf__ngram_range  \\\n",
       "41                   (1, 3)   \n",
       "28                   (1, 3)   \n",
       "44                   (1, 3)   \n",
       "14                   (1, 4)   \n",
       "31                   (1, 4)   \n",
       "36                   (1, 3)   \n",
       "40                   (1, 3)   \n",
       "39                   (1, 4)   \n",
       "38                   (1, 4)   \n",
       "\n",
       "                              param_tfidf__stop_words  \\\n",
       "41  [depending, actually, entitlement, equivalent,...   \n",
       "28                                               None   \n",
       "44                                               None   \n",
       "14                                               None   \n",
       "31  [depending, actually, entitlement, equivalent,...   \n",
       "36                                               None   \n",
       "40                                               None   \n",
       "39  [depending, actually, entitlement, equivalent,...   \n",
       "38                                               None   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "41  {'dtc__max_depth': None, 'dtc__max_features': ...                0.8   \n",
       "28  {'dtc__max_depth': 7, 'dtc__max_features': 0.8...                0.8   \n",
       "44  {'dtc__max_depth': None, 'dtc__max_features': ...                0.8   \n",
       "14  {'dtc__max_depth': 5, 'dtc__max_features': 0.8...                0.8   \n",
       "31  {'dtc__max_depth': 7, 'dtc__max_features': 0.8...                0.8   \n",
       "36  {'dtc__max_depth': None, 'dtc__max_features': ...                0.8   \n",
       "40  {'dtc__max_depth': None, 'dtc__max_features': ...                0.8   \n",
       "39  {'dtc__max_depth': None, 'dtc__max_features': ...                0.8   \n",
       "38  {'dtc__max_depth': None, 'dtc__max_features': ...                0.8   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "41           1.000000                1.0           1.000000   \n",
       "28           1.000000                1.0           1.000000   \n",
       "44           1.000000                1.0           1.000000   \n",
       "14           1.000000                1.0           1.000000   \n",
       "31           0.933333                1.0           0.933333   \n",
       "36           1.000000                1.0           0.933333   \n",
       "40           1.000000                1.0           1.000000   \n",
       "39           1.000000                1.0           1.000000   \n",
       "38           1.000000                1.0           1.000000   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "41           1.000000         0.960000        0.080000                1  \n",
       "28           0.933333         0.946667        0.077746                3  \n",
       "44           0.933333         0.946667        0.077746                3  \n",
       "14           0.933333         0.946667        0.077746                3  \n",
       "31           1.000000         0.933333        0.073030                6  \n",
       "36           0.933333         0.933333        0.073030                6  \n",
       "40           0.866667         0.933333        0.084327                8  \n",
       "39           0.866667         0.933333        0.084327                8  \n",
       "38           0.866667         0.933333        0.084327                8  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gridCV.cv_results_).sort_values(by=\"mean_test_score\",ascending=False)[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a predictions dataframe for Holiday Entitlement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_holiday = pd.DataFrame(columns = [\n",
    "            'Number of days excluding public holidays expressed if part-time',\n",
    "            'Number of days including public holidays expressed if part-time',\n",
    "            'Holiday pro-rata to full-time 25 days (silent as to public holidays)(25)',\n",
    "            'Holiday pro-rata by hrs to full-time 5.6 weeks including public holidays (or 20+8) (28)',\n",
    "            'Holiday 6.12 weeks including public holidays (30.x)',\n",
    "            'Holiday pro-rata to full-time 33 days including 8 public holidays (or 25+8) (33)',\n",
    "            'Holiday pro-rata to full-time 35 days plus 8 public holidays (43)',\n",
    "            'Holiday pro-rata to full-time 35 days plus 9 public holidays (44)',\n",
    "            'Holiday Entitlement paid as part of annual salary',\n",
    "            'Holiday Entitlement paid Dec and Jun',\n",
    "            'days_holiday',\n",
    "            'pro_rata',\n",
    "            'days_entitled',\n",
    "            'days_phol'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create rules in the matcher to match rule based categorizing several items to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "hol_matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_dec_match(matcher, doc, id, matches):\n",
    "      doc._.dec_jan = \"yes\"\n",
    "        \n",
    "def on_leave_match(matcher, doc, id, matches):\n",
    "      doc._.leave_as_salary = \"yes\"\n",
    "        \n",
    "def on_hol30x_match(matcher, doc, id, matches):\n",
    "      doc._.hol_30x = 1\n",
    "        \n",
    "def on_pro_match(matcher, doc, id, matches):\n",
    "      doc._.pro_rata = 1\n",
    "\n",
    "hol_matcher.add(\"dec_jan\", on_dec_match, [{\"LOWER\": \"twice\"},{\"LOWER\": \"yearly\"}, {\"LOWER\": \"in\"},{\"LOWER\": \"december\"},{\"LOWER\": \"and\"}, {\"LOWER\": \"june\"}])\n",
    "hol_matcher.add(\"leave_as_salary\", on_leave_match, [{\"LOWER\": \"leave\"}, {\"lower\": \"will\"},{\"lower\": \"be\"},{\"lower\": \"paid\"},{\"lower\": \"as\"},{\"lower\": \"part\"}])\n",
    "hol_matcher.add(\"hol_30x\", on_hol30x_match, [{\"LOWER\": \"6.12\"}, {\"lower\": \"weeks\"}])\n",
    "hol_matcher.add(\"pro_rata\", on_pro_match, [{\"LOWER\": \"pro\"},{\"LOWER\": \"-\", \"OP\": \"?\"}, {\"LOWER\": \"rata\"}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Spacy Doc objects from holiday extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "hol_docs = nlp.pipe(holidays_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_predictions = model.predict(holidays_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dtc = pd.get_dummies(DTC_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,doc in enumerate(hol_docs):\n",
    "           \n",
    "    matches = hol_matcher(doc)\n",
    "    \n",
    "    preds_holiday.loc[idx] = [0,0,0,0,\n",
    "                              doc._.hol_30x,\n",
    "                              0,0,0,\n",
    "                              doc._.leave_as_salary, \n",
    "                              doc._.dec_jan,\n",
    "                              get_days_holiday(doc),\n",
    "                              doc._.pro_rata,\n",
    "                              get_days_entitled(doc),\n",
    "                              get_days_phol(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'89.0% accuracy'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_results(preds_holiday,contract_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the holiday category (30x) days was not included in the decision tree classifier as there were too few examples and it hurt accuracy, also it seems that it could be easily predicted by a rule so we need to zero predictions from the DTC for examples that can be predicted as 30x by a simple Matcher rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hol30x = \"Holiday 6.12 weeks including public holidays (30.x)\" #4\n",
    "is_hol30x = (preds_holiday.loc[:,hol30x] == 1)\n",
    "\n",
    "#clear predictions for examples\n",
    "one_hot_dtc[is_hol30x] = 0\n",
    "\n",
    "days_exc = 'Number of days excluding public holidays expressed if part-time' #0\n",
    "days_inc = 'Number of days including public holidays expressed if part-time' #1\n",
    "hol25 = 'Holiday pro-rata to full-time 25 days (silent as to public holidays)(25)' #2\n",
    "hol28 = 'Holiday pro-rata by hrs to full-time 5.6 weeks including public holidays (or 20+8) (28)' #3rd \n",
    "\n",
    "hol33 = 'Holiday pro-rata to full-time 33 days including 8 public holidays (or 25+8) (33)' #5\n",
    "hol43 = 'Holiday pro-rata to full-time 35 days plus 8 public holidays (43)' #6\n",
    "hol44 = \"Holiday pro-rata to full-time 35 days plus 9 public holidays (44)\" #7\n",
    "\n",
    "dec_jan = 'Holiday Entitlement paid Dec and Jun' #8\n",
    "leave_as_sal = 'Holiday Entitlement paid as part of annual salary' #9\n",
    "\n",
    "preds_holiday.loc[:,hol28] = one_hot_dtc.loc[:,3]\n",
    "preds_holiday.loc[:,hol33] = one_hot_dtc.loc[:,5]\n",
    "preds_holiday.loc[:,hol43] = one_hot_dtc.loc[:,6]\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'98.2% accuracy'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_results(preds_holiday,contract_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_days_inc = ((preds_holiday[hol43]==1) & (preds_holiday[\"days_holiday\"]<43) & \n",
    "               (preds_holiday[\"pro_rata\"] ==1) & \n",
    "               (preds_holiday[\"days_entitled\"]==43)) | ((preds_holiday[hol33]==1) & \n",
    "                (preds_holiday[\"days_holiday\"]<33) &  (preds_holiday[\"pro_rata\"] ==1) & \n",
    "                                                       (preds_holiday[\"days_entitled\"]==33)) \n",
    "\n",
    "has_days_exc = ((preds_holiday[hol43]==1) & (preds_holiday[\"days_holiday\"]<43) & \n",
    "               (preds_holiday[\"pro_rata\"] ==1) & \n",
    "               (preds_holiday[\"days_entitled\"]<43)) | ((preds_holiday[hol33]==1) & \n",
    "                (preds_holiday[\"days_holiday\"]<33) &  (preds_holiday[\"pro_rata\"] ==1) & \n",
    "                                                       (preds_holiday[\"days_entitled\"]<33)) \n",
    "\n",
    "has_44_days = (preds_holiday[hol43]==1) & (preds_holiday[\"days_phol\"] > 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_holiday.loc[has_days_exc,days_exc] = preds_holiday.loc[has_days_exc,\"days_holiday\"]\n",
    "preds_holiday.loc[has_days_inc,days_inc] = preds_holiday.loc[has_days_inc,\"days_holiday\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate hol44 class and hol43 class previously joined together for processing by the DTC, by using nr bank/public holidays included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_holiday.loc[has_44_days,[hol43,hol44]] = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99.9% accuracy'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_results(preds_holiday,contract_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible future work , if more samples maybe Spacy text cat or a Deep learning approach with Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
