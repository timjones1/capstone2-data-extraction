{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelength - Fine Tuning a Spacy NER Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokens import Token, Span, Doc\n",
    "from spacy import displacy\n",
    "# from openpyxl import load_workbook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import wavefunctions as wf\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_excel('data\\Employee Train.xlsx',sheet_name=\"Training Dataset\")\n",
    "train_raw.sort_values(by='Employee ID',inplace=True)\n",
    "times_extract = train_raw['Times [Extract]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export text in JSON lines format to be annotated in annotation software Doccano installed locally in Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#times_export = train_raw[['Employee ID','Times [Extract]','Days per week specified','Hours per week specified']]\n",
    "#times_export.to_json('training_raw.json',orient=\"records\",lines=True)\n",
    "times_extract.to_json('training_raw.json',orient=\"records\",lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare custom Document and Span extensions to store relevant days and hours figures for downstream calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATE = \"13th October 2019 \"\n",
    "Doc.set_extension(\"specified_days\",default=0, force=True)\n",
    "Doc.set_extension(\"specified_hours\",default=0, force=True)\n",
    "Doc.set_extension(\"lunch_hours\",default=0, force=True)\n",
    "Span.set_extension(\"saved_hours\",default=0, force=True)\n",
    "Span.set_extension(\"saved_days\",default=0, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(times_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import annotated JSON lines file from Doccano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMPORT = pd.read_json(\"file.json1\",orient=\"records\",lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>meta</th>\n",
       "      <th>annotation_approver</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>585</td>\n",
       "      <td>6.1 Your normal working hours are 25 hours per...</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[34, 51, TIME], [60, 72, TIME], [76, 92, DATE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>607</td>\n",
       "      <td>Your normal working hours are between 08:45am ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[38, 56, TIME], [60, 74, DATE], [80, 88, TIME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>654</td>\n",
       "      <td>The normal working week is 37.5 hours. You are...</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[27, 37, TIME], [104, 120, DATE], [194, 210, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>635</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>612</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>599</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>646</td>\n",
       "      <td>Your normal working hours are 21 hours each we...</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[30, 48, TIME], [61, 92, DATE], [146, 162, TI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text meta  \\\n",
       "1   627                                               None   {}   \n",
       "12  585  6.1 Your normal working hours are 25 hours per...   {}   \n",
       "34  607  Your normal working hours are between 08:45am ...   {}   \n",
       "75  654  The normal working week is 37.5 hours. You are...   {}   \n",
       "56  635                                               None   {}   \n",
       "39  612                                               None   {}   \n",
       "26  599                                               None   {}   \n",
       "67  646  Your normal working hours are 21 hours each we...   {}   \n",
       "\n",
       "    annotation_approver                                             labels  \n",
       "1                   NaN                                                 []  \n",
       "12                  NaN  [[34, 51, TIME], [60, 72, TIME], [76, 92, DATE...  \n",
       "34                  NaN  [[38, 56, TIME], [60, 74, DATE], [80, 88, TIME...  \n",
       "75                  NaN  [[27, 37, TIME], [104, 120, DATE], [194, 210, ...  \n",
       "56                  NaN                                                 []  \n",
       "39                  NaN                                                 []  \n",
       "26                  NaN                                                 []  \n",
       "67                  NaN  [[30, 48, TIME], [61, 92, DATE], [146, 162, TI...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_IMPORT.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat Annotations into Entity Labels for each text example, labels are stored as a dictionary of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entity_tags(labels_list):\n",
    "    '''Format imported labels from Doccano into entity tags'''\n",
    "    entity_dict = {} \n",
    "    entity_dict[\"entities\"] = tuple(labels_list)\n",
    "    \n",
    "    return entity_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMPORT['entities'] = TRAIN_IMPORT['labels'].apply(create_entity_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine text and entity tags into the correct training data format for a Spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_2 = []\n",
    "for _, row in TRAIN_IMPORT[['text','entities']].iterrows():\n",
    "    training_example = (row['text'], row['entities'])\n",
    "    TRAINING_DATA_2.append(training_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create named Entity Recognition model inside a spacy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.create_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.neural.optimizers.Optimizer at 0x21ec00ddf70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(TRAINING_DATA_2,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timjo\\Anaconda3\\envs\\wave\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"The normal working week is 37.5 hours. You are emp...\" with entities \"[[27, 37, 'TIME'], [104, 120, 'DATE'], [194, 207, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\timjo\\Anaconda3\\envs\\wave\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"The normal working week is 37.5 hours. You are emp...\" with entities \"[[27, 37, 'TIME'], [105, 121, 'DATE'], [335, 344, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\timjo\\Anaconda3\\envs\\wave\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Your normal working hours are 24 hours each week. ...\" with entities \"[[30, 48, 'TIME'], [110, 123, 'TIME'], [214, 222, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\timjo\\Anaconda3\\envs\\wave\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Your normal working hours are 08.45 to 17.45 three...\" with entities \"[[30, 44, 'TIME'], [44, 64, 'DATE'], [84, 92, 'TIM...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    }
   ],
   "source": [
    "for itn in range(10):\n",
    "    random.shuffle(train_data)\n",
    "    for batch in spacy.util.minibatch(train_data, size=2):\n",
    "        texts = [text for text,annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        nlp.update(texts, annotations)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(times_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp(\"Your normal working hours are 40 hours per week Your specific working hours within this will be instructed by your line manager and will be in the campus routines with breaks and a 1 hour unpaid lunch break.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "â€¢ The normal working hours are 8.45am to 5.3opm), Monday to Friday, with breaks, and a one hour lunch."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40 hours per week, 1 hour)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1.0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf.extract_specified_times(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
