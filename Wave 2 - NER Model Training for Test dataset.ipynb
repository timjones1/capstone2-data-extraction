{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelength - Fine Tuning a Spacy NER Model - Final Training ready for Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokens import Token, Span, Doc\n",
    "from spacy import displacy\n",
    "# from openpyxl import load_workbook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import wavefunctions as wf\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_excel('data\\Employee Train.xlsx',sheet_name=\"Training Dataset\")\n",
    "train_raw.sort_values(by='Employee ID',inplace=True)\n",
    "times_extract = train_raw['Times [Extract]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export text in JSON lines format to be annotated in annotation software Doccano installed locally in Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#times_export = train_raw[['Employee ID','Times [Extract]','Days per week specified','Hours per week specified']]\n",
    "#times_export.to_json('training_raw.json',orient=\"records\",lines=True)\n",
    "times_extract.to_json('JSON/training_raw.json',orient=\"records\",lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare custom Document and Span extensions to store relevant days and hours figures for downstream calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATE = \"13th October 2019 \"\n",
    "Doc.set_extension(\"specified_days\",default=0, force=True)\n",
    "Doc.set_extension(\"specified_hours\",default=0, force=True)\n",
    "Doc.set_extension(\"lunch_hours\",default=0, force=True)\n",
    "Span.set_extension(\"saved_hours\",default=0, force=True)\n",
    "Span.set_extension(\"saved_days\",default=0, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(times_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import annotated JSON lines file from Doccano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMPORT = pd.read_json(\"file.json1\",orient=\"records\",lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>meta</th>\n",
       "      <th>annotation_approver</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>643</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>579</td>\n",
       "      <td>6.1 Your normal working hours are 08.45 to 17....</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[34, 48, TIME], [68, 76, TIME], [89, 102, DATE]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>611</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>591</td>\n",
       "      <td>6.1 Your normal working hours are 08.45 to 17....</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[34, 48, TIME], [50, 67, DATE], [87, 95, TIME]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>599</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>626</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>633</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>610</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text meta  \\\n",
       "64  643                                               None   {}   \n",
       "6   579  6.1 Your normal working hours are 08.45 to 17....   {}   \n",
       "38  611                                               None   {}   \n",
       "18  591  6.1 Your normal working hours are 08.45 to 17....   {}   \n",
       "26  599                                               None   {}   \n",
       "0   626                                               None   {}   \n",
       "54  633                                               None   {}   \n",
       "37  610                                               None   {}   \n",
       "\n",
       "    annotation_approver                                             labels  \n",
       "64                  NaN                                                 []  \n",
       "6                   NaN  [[34, 48, TIME], [68, 76, TIME], [89, 102, DATE]]  \n",
       "38                  NaN                                                 []  \n",
       "18                  NaN   [[34, 48, TIME], [50, 67, DATE], [87, 95, TIME]]  \n",
       "26                  NaN                                                 []  \n",
       "0                   NaN                                                 []  \n",
       "54                  NaN                                                 []  \n",
       "37                  NaN                                                 []  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_IMPORT.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat Annotations into Entity Labels for each text example, labels are stored as a dictionary of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entity_tags(labels_list):\n",
    "    '''Format imported labels from Doccano into entity tags'''\n",
    "    entity_dict = {} \n",
    "    entity_dict[\"entities\"] = tuple(labels_list)\n",
    "    \n",
    "    return entity_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMPORT['entities'] = TRAIN_IMPORT['labels'].apply(create_entity_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine text and entity tags into the correct training data format for a Spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_2 = []\n",
    "for _, row in TRAIN_IMPORT[['text','entities']].iterrows():\n",
    "    training_example = (row['text'], row['entities'])\n",
    "    TRAINING_DATA_2.append(training_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create named Entity Recognition model inside a spacy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.create_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.neural.optimizers.Optimizer at 0x21ec00ddf70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(TRAINING_DATA_2,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timjo\\Anaconda3\\envs\\wave\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"The normal working week is 37.5 hours. You are emp...\" with entities \"[[27, 37, 'TIME'], [104, 120, 'DATE'], [194, 207, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\timjo\\Anaconda3\\envs\\wave\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"The normal working week is 37.5 hours. You are emp...\" with entities \"[[27, 37, 'TIME'], [105, 121, 'DATE'], [335, 344, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\timjo\\Anaconda3\\envs\\wave\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Your normal working hours are 24 hours each week. ...\" with entities \"[[30, 48, 'TIME'], [110, 123, 'TIME'], [214, 222, ...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\timjo\\Anaconda3\\envs\\wave\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Your normal working hours are 08.45 to 17.45 three...\" with entities \"[[30, 44, 'TIME'], [44, 64, 'DATE'], [84, 92, 'TIM...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    }
   ],
   "source": [
    "for itn in range(10):\n",
    "    random.shuffle(train_data)\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA_2, size=2):\n",
    "        texts = [text for text,annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        nlp.update(texts, annotations)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = [text for text, _ in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(times_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nlp(\"Your normal working hours are 40 hours per week Your specific working hours within this will be instructed by your line manager and will be in the campus routines with breaks and a 1 hour unpaid lunch break.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Your normal working hours are 40 hours per week Your specific working hours within this will be instructed by your line manager and will be in the campus routines with breaks and a 1 hour unpaid lunch break."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"final model/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
